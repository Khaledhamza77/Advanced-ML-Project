# -*- coding: utf-8 -*-
"""Fine-Tuning Distilled Models

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YRqQUQCowkHbw1sjHtPG3oOdZPbhfMbt

#Setting Up
"""

!pip install --quiet datasets

pip install accelerate>=0.21.0

from google.colab import drive
import pandas as pd
from tqdm import tqdm
import gc
drive.mount('/content/drive')

from datasets import load_dataset
snli_dataset = load_dataset("snli")

mnli_dataset = load_dataset("multi_nli")

from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from datasets import load_dataset

output_dir = '/content/drive/My Drive/MNLI_project/distildeberta'

# Load MNLI dataset
mnli_dataset = load_dataset("multi_nli")

# Choose a partition (e.g., 'train', 'validation_matched', 'validation_mismatched')
partition = 'validation_matched'

# Load DeBERTa tokenizer and model
tokenizer = AutoTokenizer.from_pretrained("deepvk/deberta-v1-distill")
model = AutoModelForSequenceClassification.from_pretrained("deepvk/deberta-v1-distill", num_labels=3)  # 3 labels for MNLI: entailment, neutral, contradiction

# Tokenize input texts
def tokenize_function(example):
    return tokenizer(
        example["premise"],
        example["hypothesis"],
        truncation=True,
        max_length=128,  # Adjust the maximum sequence length as needed
        padding="max_length",
        return_tensors="pt",
    )

tokenized_dataset = mnli_dataset[partition].map(tokenize_function, batched=True)

# Define training arguments
training_args = TrainingArguments(
    output_dir=output_dir,  # Output directory in Google Drive
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=2,
    logging_dir='./logs',
)

# Define compute_metrics function
def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = predictions.argmax(axis=1)
    return {"accuracy": (predictions == labels).mean()}

# Define Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset,
    eval_dataset=tokenized_dataset,
    compute_metrics=compute_metrics  # Specify the compute_metrics function
)

# Fine-tune DeBERTa
trainer.train()

# Evaluate the model
trainer.evaluate()

from datasets import load_metric
# Load the fine-tuned model
fine_tuned_model = DistilBertForSequenceClassification.from_pretrained('/content/drive/MyDrive/MNLI_project/distildeberta/checkpoint-1000')

# Define Trainer with the loaded model
eval_trainer = Trainer(
    model=fine_tuned_model,
)

# Load a small sample of the MNLI validation dataset
sample_size = 100  # Define the size of the sample
small_dataset = mnli_dataset[partition].shuffle(seed=42).select(range(sample_size))

# Tokenize the small dataset
tokenized_small_dataset = small_dataset.map(tokenize_function, batched=True)

# Evaluate the fine-tuned model on the small dataset
evaluation_result = eval_trainer.evaluate(eval_dataset=tokenized_small_dataset)

sample_size = 100  # Define the size of the sample
small_dataset = mnli_dataset[partition].shuffle(seed=42).select(range(sample_size))
# Load accuracy metric
metric = load_metric("accuracy")

# Get predictions from the fine-tuned model on the small dataset
predictions = eval_trainer.predict(tokenized_small_dataset)

# Get predicted labels
predicted_labels = predictions.predictions.argmax(axis=1)

# Get actual labels from the small dataset
actual_labels = small_dataset['label']

# Compute accuracy
accuracy = metric.compute(predictions=predicted_labels, references=actual_labels)

# Print accuracy
print("Accuracy:", accuracy)

"""# DistilBERT Fine Tuning"""

import torch
from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, Trainer, TrainingArguments
from datasets import load_dataset, Dataset

import torch
from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, Trainer, TrainingArguments
from datasets import load_dataset, Dataset
output_dir = '/content/drive/My Drive/MNLI_project/distilbert'
# Load MNLI dataset
mnli_dataset = load_dataset("multi_nli")

# Choose a partition (e.g., 'train', 'validation_matched', 'validation_mismatched')
partition = 'validation_matched'

# Load DistilBERT tokenizer and model
tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")
model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=3)  # 3 labels for MNLI: entailment, neutral, contradiction

# Tokenize input texts
def tokenize_function(example):
    return tokenizer(
        example["premise"],
        example["hypothesis"],
        truncation=True,
        max_length=128,  # Adjust the maximum sequence length as needed
        padding="max_length",
        return_tensors="pt",
    )

tokenized_dataset = mnli_dataset[partition].map(tokenize_function, batched=True)

# Define training arguments
training_args = TrainingArguments(
    output_dir=output_dir,  # Output directory in Google Drive
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=2,
    logging_dir='./logs',
)

# Define Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset,
    eval_dataset=tokenized_dataset,  # You can change this to a separate validation dataset if available
)

# Fine-tune DistilBERT
trainer.train()

# Evaluate the model
trainer.evaluate()

from datasets import load_metric
# Load the fine-tuned model
fine_tuned_model = DistilBertForSequenceClassification.from_pretrained('/content/drive/MyDrive/MNLI_project/distilbert/checkpoint-2000')

# Define Trainer with the loaded model
eval_trainer = Trainer(
    model=fine_tuned_model,
)

# Load a small sample of the MNLI validation dataset
sample_size = 100  # Define the size of the sample
small_dataset = mnli_dataset[partition].shuffle(seed=42).select(range(sample_size))

# Tokenize the small dataset
tokenized_small_dataset = small_dataset.map(tokenize_function, batched=True)

# Evaluate the fine-tuned model on the small dataset
evaluation_result = eval_trainer.evaluate(eval_dataset=tokenized_small_dataset)

sample_size = 100  # Define the size of the sample
small_dataset = mnli_dataset[partition].shuffle(seed=42).select(range(sample_size))
# Load accuracy metric
metric = load_metric("accuracy")

# Get predictions from the fine-tuned model on the small dataset
predictions = eval_trainer.predict(tokenized_small_dataset)

# Get predicted labels
predicted_labels = predictions.predictions.argmax(axis=1)

# Get actual labels from the small dataset
actual_labels = small_dataset['label']

# Compute accuracy
accuracy = metric.compute(predictions=predicted_labels, references=actual_labels)

# Print accuracy
print("Accuracy:", accuracy)

from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, Trainer, TrainingArguments
from datasets import load_dataset, load_metric

# Load the original model
original_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')
original_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')

# Load MNLI dataset
mnli_dataset = load_dataset("multi_nli")
partition = 'validation_mismatched'

# Tokenize input texts
def tokenize_function(example):
    return original_tokenizer(
        example["premise"],
        example["hypothesis"],
        truncation=True,
        max_length=128,
        padding="max_length",
        return_tensors="pt",
    )

# Filter out examples with label two
mnli_dataset_filtered = mnli_dataset[partition].filter(lambda example: example["label"] != 2)

# Load a small sample of the MNLI validation dataset
sample_size = 100
small_dataset = mnli_dataset_filtered.shuffle(seed=42).select(range(sample_size))

# Tokenize the small dataset
tokenized_small_dataset = small_dataset.map(tokenize_function, batched=True)

# Define Trainer with the original model
original_trainer = Trainer(
    model=original_model,
)

# Evaluate the original model on the small dataset
original_evaluation_result = original_trainer.evaluate(eval_dataset=tokenized_small_dataset)

# Load accuracy metric
metric = load_metric("accuracy")

# Get predictions from the original model on the small dataset
original_predictions = original_trainer.predict(tokenized_small_dataset)

# Get predicted labels
original_predicted_labels = original_predictions.predictions.argmax(axis=1)

# Get actual labels from the small dataset
original_actual_labels = small_dataset['label']

# Compute accuracy for the original model
original_accuracy = metric.compute(predictions=original_predicted_labels, references=original_actual_labels)

# Print accuracy for the original model
print("Original Model Accuracy:", original_accuracy)

"""# DistilBART Fine Tuning"""

from transformers import BartForSequenceClassification, BartTokenizer
from datasets import load_dataset
from transformers import Trainer, TrainingArguments

# Define output directory
output_dir = '/content/drive/MyDrive/MNLI_project/DistilBart'

# Load BART tokenizer and model
tokenizer = BartTokenizer.from_pretrained("valhalla/distilbart-mnli-12-9")
model = BartForSequenceClassification.from_pretrained("valhalla/distilbart-mnli-12-1", num_labels=3)

# Tokenize input texts and add labels
def tokenize_function(example):
    tokenized_input = tokenizer(
        example["premise"],
        example["hypothesis"],
        truncation=True,
        max_length=128,
        padding="max_length",
        return_tensors="pt",
    )
    tokenized_input["labels"] = example["label"]  # Add labels to the tokenized inputs
    return tokenized_input

from transformers import BartForSequenceClassification, BartTokenizer
from datasets import load_dataset
from transformers import Trainer, TrainingArguments

# Define output directory
output_dir = '/content/drive/MyDrive/MNLI_project/DistilBart'

# Load BART tokenizer and model
tokenizer = BartTokenizer.from_pretrained("valhalla/distilbart-mnli-12-1")
model = BartForSequenceClassification.from_pretrained("valhalla/distilbart-mnli-12-1", num_labels=3)

# Load SNLI dataset
snli_dataset = load_dataset("snli")
partition = 'train'

# Filter out examples with missing labels
snli_dataset = snli_dataset[partition].filter(lambda example: example['label'] != -1)

# Tokenize input texts and add labels
def tokenize_function(example):
    tokenized_input = tokenizer(
        example["premise"],
        example["hypothesis"],
        truncation=True,
        max_length=128,
        padding="max_length",
        return_tensors="pt",
    )
    tokenized_input["labels"] = example["label"]  # Add labels to the tokenized inputs
    return tokenized_input

# Define the size of the sample
sample_size = 1227

# Load a small sample of the SNLI dataset
small_dataset = snli_dataset.shuffle(seed=42).select(range(sample_size))

# Tokenize the small dataset
tokenized_dataset = small_dataset.map(tokenize_function, batched=True)

# Define training arguments
training_args = TrainingArguments(
    output_dir=output_dir,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=2,
    logging_dir='./logs',
)

# Define Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset,
    eval_dataset=tokenized_dataset,
)

# Fine-tune BART
trainer.train()

# Evaluate the model
trainer.evaluate()

from datasets import load_dataset
from transformers import BartForSequenceClassification, Trainer, TrainingArguments
from transformers import BartTokenizer
from datasets import load_metric

# Load the fine-tuned model
fine_tuned_model = BartForSequenceClassification.from_pretrained('/content/drive/MyDrive/MNLI_project/DistilBart/checkpoint-1000')

# Load the tokenizer
tokenizer = BartTokenizer.from_pretrained('valhalla/distilbart-mnli-12-1')

# Load SNLI dataset
snli_dataset = load_dataset("snli")

# Choose the partition you want to evaluate on
partition = 'test'

# Load a small sample of the SNLI validation dataset
sample_size = 100

# Tokenize the small dataset
def tokenize_function(example):
    return tokenizer(
        example["premise"],
        example["hypothesis"],
        truncation=True,
        max_length=128,
        padding="max_length",
        return_tensors="pt",
    )

tokenized_small_dataset = small_dataset.map(tokenize_function, batched=True)

# Define Trainer with the loaded model
eval_trainer = Trainer(
    model=fine_tuned_model,
)

# Evaluate the fine-tuned model on the small dataset
metric = load_metric("accuracy")

# Get predictions from the fine-tuned model on the small dataset
predictions = eval_trainer.predict(tokenized_small_dataset)

predicted_labels = predictions.predictions[0].argmax(axis=1)

# Get actual labels from the small dataset
actual_labels = small_dataset['label']

# Compute accuracy
accuracy = metric.compute(predictions=predicted_labels, references=actual_labels)

# Print accuracy
print("Accuracy:", accuracy)

from datasets import load_dataset
from transformers import BartForSequenceClassification, Trainer, TrainingArguments
from transformers import BartTokenizer
from datasets import load_metric

# Load the fine-tuned model
fine_tuned_model = BartForSequenceClassification.from_pretrained('valhalla/distilbart-mnli-12-1')

# Load the tokenizer
tokenizer = BartTokenizer.from_pretrained('valhalla/distilbart-mnli-12-1')

# Load SNLI dataset
snli_dataset = load_dataset("snli")

# Choose the partition you want to evaluate on
partition = 'validation'

# Load a small sample of the SNLI validation dataset
sample_size = 100

# Tokenize the small dataset
def tokenize_function(example):
    return tokenizer(
        example["premise"],
        example["hypothesis"],
        truncation=True,
        max_length=128,
        padding="max_length",
        return_tensors="pt",
    )

tokenized_small_dataset = small_dataset.map(tokenize_function, batched=True)

# Define Trainer with the loaded model
eval_trainer = Trainer(
    model=fine_tuned_model,
)

# Evaluate the fine-tuned model on the small dataset
metric = load_metric("accuracy")

# Get predictions from the fine-tuned model on the small dataset
predictions = eval_trainer.predict(tokenized_small_dataset)

# Get predicted labels
predicted_labels = predictions.predictions[0].argmax(axis=1)

# Get actual labels from the small dataset
actual_labels = small_dataset['label']

# Compute accuracy
accuracy = metric.compute(predictions=predicted_labels, references=actual_labels)

# Print accuracy
print("Accuracy:", accuracy)

from datasets import load_metric
# Load the fine-tuned model
fine_tuned_model = BartForSequenceClassification.from_pretrained('/content/drive/MyDrive/MNLI_project/DistilBart/checkpoint-1000')
tokenizer = BartTokenizer.from_pretrained('valhalla/distilbart-mnli-12-1')

# Define Trainer with the loaded model
eval_trainer = Trainer(
    model=fine_tuned_model,
)

# Load a small sample of the MNLI validation dataset
sample_size = 100  # Define the size of the sample
small_dataset = mnli_dataset[partition].shuffle(seed=42).select(range(sample_size))

# Tokenize the small dataset
tokenized_small_dataset = small_dataset.map(tokenize_function, batched=True)

# Evaluate the fine-tuned model on the small dataset
evaluation_result = eval_trainer.evaluate(eval_dataset=tokenized_small_dataset)

sample_size = 100  # Define the size of the sample
small_dataset = mnli_dataset[partition].shuffle(seed=42).select(range(sample_size))
# Load accuracy metric
metric = load_metric("accuracy")

# Get predictions from the fine-tuned model on the small dataset
predictions = eval_trainer.predict(tokenized_small_dataset)

# Get predicted labels
predicted_labels = predictions.predictions[0].argmax(axis=1)

# Get actual labels from the small dataset
actual_labels = small_dataset['label']

# Compute accuracy
accuracy = metric.compute(predictions=predicted_labels, references=actual_labels)

# Print accuracy
print("Accuracy:", accuracy)

from datasets import load_metric
# Load the fine-tuned model
fine_tuned_model = BartForSequenceClassification.from_pretrained('valhalla/distilbart-mnli-12-1')
tokenizer = BartTokenizer.from_pretrained('valhalla/distilbart-mnli-12-1')
partition = 'validation_mismatched'
# Define Trainer with the loaded model
eval_trainer = Trainer(
    model=fine_tuned_model,
)

# Load a small sample of the MNLI validation dataset
sample_size = 100  # Define the size of the sample
small_dataset = mnli_dataset[partition].shuffle(seed=42).select(range(sample_size))

# Tokenize the small dataset
tokenized_small_dataset = small_dataset.map(tokenize_function, batched=True)

# Evaluate the fine-tuned model on the small dataset
evaluation_result = eval_trainer.evaluate(eval_dataset=tokenized_small_dataset)

sample_size = 100  # Define the size of the sample
small_dataset = mnli_dataset[partition].shuffle(seed=42).select(range(sample_size))
# Load accuracy metric
metric = load_metric("accuracy")

# Get predictions from the fine-tuned model on the small dataset
predictions = eval_trainer.predict(tokenized_small_dataset)

# Get predicted labels
predicted_labels = predictions.predictions[0].argmax(axis=1)

# Get actual labels from the small dataset
actual_labels = small_dataset['label']

# Compute accuracy
accuracy = metric.compute(predictions=predicted_labels, references=actual_labels)

# Print accuracy
print("Accuracy:", accuracy)

from datasets import load_metric
# Load the fine-tuned model
fine_tuned_model = BartForSequenceClassification.from_pretrained('facebook/bart-large-mnli')
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-mnli')
partition = 'validation_mismatched'
# Define Trainer with the loaded model
eval_trainer = Trainer(
    model=fine_tuned_model,
)

# Load a small sample of the MNLI validation dataset
sample_size = 100  # Define the size of the sample
small_dataset = mnli_dataset[partition].shuffle(seed=42).select(range(sample_size))

# Tokenize the small dataset
tokenized_small_dataset = small_dataset.map(tokenize_function, batched=True)

# Evaluate the fine-tuned model on the small dataset
evaluation_result = eval_trainer.evaluate(eval_dataset=tokenized_small_dataset)

sample_size = 100  # Define the size of the sample
small_dataset = mnli_dataset[partition].shuffle(seed=42).select(range(sample_size))
# Load accuracy metric
metric = load_metric("accuracy")

# Get predictions from the fine-tuned model on the small dataset
predictions = eval_trainer.predict(tokenized_small_dataset)

# Get predicted labels
predicted_labels = predictions.predictions[0].argmax(axis=1)

# Get actual labels from the small dataset
actual_labels = small_dataset['label']

# Compute accuracy
accuracy = metric.compute(predictions=predicted_labels, references=actual_labels)

# Print accuracy
print("Accuracy:", accuracy)

"""# Distil Roberta"""

from transformers import RobertaForSequenceClassification, RobertaTokenizer
from datasets import load_dataset
from transformers import Trainer, TrainingArguments

# Define output directory
output_dir = '/content/drive/MyDrive/MNLI_project/DistilRoberta'

# Load DistilRoberta tokenizer and model
tokenizer = RobertaTokenizer.from_pretrained("distilbert/distilroberta-base")
model = RobertaForSequenceClassification.from_pretrained("distilbert/distilroberta-base", num_labels=3)

# Load MNLI dataset
mnli_dataset = load_dataset("multi_nli")

# Choose a partition (e.g., 'validation_matched', 'validation_mismatched')
partition = 'train'

# Filter out examples with missing labels
mnli_dataset_filtered = mnli_dataset[partition].filter(lambda example: example['label'] != -1)

# Tokenize input texts and add labels
def tokenize_function(example):
    tokenized_input = tokenizer(
        example["premise"],
        example["hypothesis"],
        truncation=True,
        max_length=128,
        padding="max_length",
        return_tensors="pt",
    )
    tokenized_input["labels"] = example["label"]  # Add labels to the tokenized inputs
    return tokenized_input

# Define the size of the sample
sample_size = 4000

# Load a small sample of the filtered MNLI dataset
small_dataset = mnli_dataset_filtered.shuffle(seed=42).select(range(sample_size))

# Tokenize the small dataset
tokenized_dataset = small_dataset.map(tokenize_function, batched=True)

# Define training arguments
training_args = TrainingArguments(
    output_dir=output_dir,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=2,
    logging_dir='./logs',
)

# Define Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset,
    eval_dataset=tokenized_dataset,
)

# Fine-tune DistilRoberta
trainer.train()

# Evaluate the model
evaluation_result = trainer.evaluate()

# Print evaluation result
print(evaluation_result)

from datasets import load_metric

fine_tuned_model = RobertaForSequenceClassification.from_pretrained('/content/drive/MyDrive/MNLI_project/DistilRoberta/checkpoint-1000')
partition = 'test'
# Define Trainer with the loaded model
eval_trainer = Trainer(
    model=fine_tuned_model,
)

# Load a small sample of the MNLI validation dataset
sample_size = 100

# Load a small sample of the SNLI dataset
small_dataset = mnli_dataset_filtered.shuffle(seed=42).select(range(sample_size))

# Tokenize the small dataset
tokenized_dataset = small_dataset.map(tokenize_function, batched=True)

# Tokenize the small dataset
tokenized_small_dataset = small_dataset.map(tokenize_function, batched=True)

# Evaluate the fine-tuned model on the small dataset
evaluation_result = eval_trainer.evaluate(eval_dataset=tokenized_small_dataset)

# Load accuracy metric
metric = load_metric("accuracy")

# Get predictions from the fine-tuned model on the small dataset
predictions = eval_trainer.predict(tokenized_small_dataset)

# Get predicted labels
predicted_labels = predictions.predictions.argmax(axis=1)

# Get actual labels from the small dataset
actual_labels = small_dataset['label']

# Compute accuracy
accuracy = metric.compute(predictions=predicted_labels, references=actual_labels)

# Print accuracy
print("Accuracy:", accuracy)

from datasets import load_metric

fine_tuned_model = RobertaForSequenceClassification.from_pretrained('distilbert/distilroberta-base')
partition = 'test'
# Define Trainer with the loaded model
eval_trainer = Trainer(
    model=fine_tuned_model,
)

# Load a small sample of the MNLI validation dataset
sample_size = 100

# Load a small sample of the SNLI dataset
small_dataset = mnli_dataset_filtered.shuffle(seed=42).select(range(sample_size))

# Tokenize the small dataset
tokenized_dataset = small_dataset.map(tokenize_function, batched=True)

# Tokenize the small dataset
tokenized_small_dataset = small_dataset.map(tokenize_function, batched=True)

# Evaluate the fine-tuned model on the small dataset
evaluation_result = eval_trainer.evaluate(eval_dataset=tokenized_small_dataset)

# Load accuracy metric
metric = load_metric("accuracy")

# Get predictions from the fine-tuned model on the small dataset
predictions = eval_trainer.predict(tokenized_small_dataset)

# Get predicted labels
predicted_labels = predictions.predictions.argmax(axis=1)

# Get actual labels from the small dataset
actual_labels = small_dataset['label']

# Compute accuracy
accuracy = metric.compute(predictions=predicted_labels, references=actual_labels)

# Print accuracy
print("Accuracy:", accuracy)